---
layout: portEntry
title: Video Visits
methods: Qualitative Survey | User Interviews | Service Design
description: Video Visits is a complex service that cuts across many digital and non-digital touchpoints. I led research to help identify and address pain points that were impacting our connection rates. I worked with different teams to roadmap improvements that simplified a patients experience.
permalink: /VideoVisits/
---
Video Visits is a telehealth service that allows Kaiser Permanente patients get faster access to care using a camera equipped computer or mobile device.

The research project was intended to help further streamline the Video Visits experience and improve connectivity rates. Video Visits is a complex as it mixes service design and interaction design throughout a variety of different touchpoints.

![Video Visit in action]({{site.url}}/images/projects/VideoVisits/live-session.png)

## At a Glance

*Project Team*
  - My role: Lead Researcher
  - Two user researchers providing support
  - A team consisting of individuals responsible for different touchpoints across the service

*Goal of Project*
  - Identify what factor(s) may be leading to unsuccessful Video Visits
  - Provide actionable recommendations to improve connection rates.

*Outcomes*
- Two new features
- Improved Video Visit on-boarding
- Findings became a key influencing factor in renaming the app that contains Video Visits from "KP Preventive Care" to "My Doctor Online"

## Stakeholder Interviews: Determining Research Scope
I met with the Video Visits team to discuss what they were hoping to learn and what decisions needed to be informed. At this time, I also requested quantitative data to get an idea of what was happening with Video Visits with intention of being able to discover "why". From the discussions and the analysis of the data I learned...

*Project Challenges*
- Quantitative data was mainly focused on the Video Visit outcomes and not measurements throughout the service.
- No clear consensus across the service teams about what parts of the process may be problematic for users.
- Owners of specific parts of the service wanted to prioritize and validate their own hypothesis.
- Quantitative data was owned by different teams and was not easily accessible.

*Goals* We wanted to identify contributing factors that reduced Video Visit success rates. In order to increase the rate of connection, we primarily chose to target two groups.
- "Patient did not join": The clinician joined but the patient did not.
- "Neither joined": A Video Visit where neither the patient nor clinician joined.

## Developing Study Approach
Given there were no specific areas of the service to focus on, I suggested to the team that we would evaluate the entire service from when an appointment is booked to the time a Video Visit fails. The methodology would have to be open enough to identify potential pain points at any point in the experience, with the hope that some patterns would emerge to provide direction to the various teams involved.

*1st Method: Survey* A survey provided us quick and easy access to a large pool of patients who recently had unsuccessful Video Visits. I designed the survey with questions to test specific team hypothesis with finite possibilities and open-ended question identify potential pain points for patients.

<figure>
  <img src="{{site.url}}/images/projects/VideoVisits/survey-example.png" alt="Example of questions from survey">
  <figcaption>Two of the questions displayed on the survey</figcaption>
</figure>

*2nd Method: User Interviews* With the help of some of my fellow researchers, we conducted follow-up interviews with survey respondents. This allowed us to gather deeper insights to patients' survey responses than if we had used the survey alone.

*3rd Method: Service Design Blueprint* We created a high-level service design blueprint that would help capture knowledge across teams and act as starting point for further evaluation of Video Visits in the future.

## Key Research Findings
- Patients did not know where to begin the setup process for Video Visits.
- Not all patients received (or remember receiving) email instructions or reminders
- Patients used the wrong Kaiser Permanente app due to similarities in the app name. (Kaiser Permanente Preventitive Care vs Kaiser Permanente)
- We received a disproportionately high survey response rates from patients whose doctor never arrived to their appointment (Using data logs, we confirmed that in many cases the doctor was simply late by 5-10 minutes).

## Outcomes
- New clinician-facing feature allowing them to notify patients of a late start.
- Led to the implementation of an email that is sent to all patients 24 hours before their appointment giving them direct access points to the web app or mobile app for Video Visits.
- Findings from this research became a key factor in rebranding the "KP Preventive Care" app to "My Doctor Online".
- High-level service blue print that captures existing data, group knowledge, and standing questions.
<figure>
  <img src="{{site.url}}/images/projects/VideoVisits/service-blueprint.png" alt="Video Visits Service Blueprint">
  <figcaption>High-level service blueprint for Video Visits</figcaption>
</figure>

## Future Research
With the preliminary research completed, a large amount of new questions were opened up to be answered by qualitative and quantitative data. On-going research will be conducted using a random sample of users and we will also speak to specific users through more data-driven targeting. The service blueprint will be expanded into more concrete scenarios as we learn more over time.
